{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Basics of Neural Networks\n",
    "* <b>Learning Objective:</b> In the entrance exam, we asked you to implement a K-NN classifier to classify some tiny images extracted from CIFAR-10 dataset. Probably many of you noticed that the performances were quite bad. In this problem, you are going to implement a basic multi-layer fully connected neural network to perform the same classification task.\n",
    "* <b>Provided Code:</b> We provide the skeletons of classes you need to complete. Forward checking and gradient checkings are provided for verifying your implementation as well.\n",
    "* <b>TODOs:</b> You are asked to implement the forward passes and backward passes for standard layers and loss functions, various widely-used optimizers, and part of the training procedure. And finally we want you to train a network from scratch on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from lib.fully_conn import *\n",
    "from lib.layer_utils import *\n",
    "from lib.grad_check import *\n",
    "from lib.datasets import *\n",
    "from lib.optim import *\n",
    "from lib.train import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data (CIFAR-10)\n",
    "Run the following code block to load in the properly splitted CIFAR-10 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: data_train Shape: (49000, 3, 32, 32)\n",
      "Name: labels_train Shape: (49000,)\n",
      "Name: data_val Shape: (1000, 3, 32, 32)\n",
      "Name: labels_val Shape: (1000,)\n",
      "Name: data_test Shape: (1000, 3, 32, 32)\n",
      "Name: labels_test Shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "data = CIFAR10_data()\n",
    "for k, v in list(data.items()):\n",
    "    print (\"Name: {} Shape: {}\".format(k, v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Standard Layers\n",
    "You will now implement all the following standard layers commonly seen in a fully connected neural network. Please refer to the file layer_utils.py under the directory lib. Take a look at each class skeleton, and we will walk you through the network layer by layer. We provide results of some examples we pre-computed for you for checking the forward pass, and also the gradient checking for the backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FC Forward\n",
    "In the class skeleton \"fc\", please complete the forward pass in function \"forward\", the input to the fc layer may not be of dimension (batch size, features size), it could be an image or any higher dimensional data. Make sure that you handle this dimensionality issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference:  2.48539291792e-09\n"
     ]
    }
   ],
   "source": [
    "# Test the fc forward function\n",
    "input_bz = 3\n",
    "input_dim = (6, 5, 4)\n",
    "output_dim = 4\n",
    "\n",
    "input_size = input_bz * np.prod(input_dim)\n",
    "weight_size = output_dim * np.prod(input_dim)\n",
    "\n",
    "single_fc = fc(np.prod(input_dim), output_dim, init_scale=0.02, name=\"fc_test\")\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(input_bz, *input_dim)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_dim), output_dim)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim)\n",
    "\n",
    "single_fc.params[single_fc.w_name] = w\n",
    "single_fc.params[single_fc.b_name] = b\n",
    "\n",
    "out = single_fc.forward(x)\n",
    "\n",
    "correct_out = np.array([[0.70157129, 0.83483484, 0.96809839, 1.10136194],\n",
    "                        [1.86723094, 2.02561647, 2.18400199, 2.34238752],\n",
    "                        [3.0328906,  3.2163981,  3.3999056,  3.5834131]])\n",
    "\n",
    "# Compare your output with the above pre-computed ones. \n",
    "# The difference should not be larger than 1e-8\n",
    "print (\"Difference: \", rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FC Backward\n",
    "Please complete the function \"backward\" as the backward pass of the fc layer. Follow the instructions in the comments to store gradients into the predefined dictionaries in the attributes of the class. Parameters of the layer are also stored in the predefined dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx Error:  8.83406012339e-09\n",
      "dw Error:  6.2329993009e-10\n",
      "db Error:  1.05335945795e-11\n"
     ]
    }
   ],
   "source": [
    "# Test the fc backward function\n",
    "x = np.random.randn(10, 2, 2, 3)\n",
    "w = np.random.randn(12, 10)\n",
    "b = np.random.randn(10)\n",
    "dout = np.random.randn(10, 10)\n",
    "\n",
    "single_fc = fc(np.prod(x.shape[1:]), 10, init_scale=5e-2, name=\"fc_test\")\n",
    "single_fc.params[single_fc.w_name] = w\n",
    "single_fc.params[single_fc.b_name] = b\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: single_fc.forward(x), x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: single_fc.forward(x), w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: single_fc.forward(x), b, dout)\n",
    "\n",
    "out = single_fc.forward(x)\n",
    "dx = single_fc.backward(dout)\n",
    "dw = single_fc.grads[single_fc.w_name]\n",
    "db = single_fc.grads[single_fc.b_name]\n",
    "\n",
    "# dx_num = dx_num.reshape((-1, np.prod(x.shape[1:]))) # If I can add this row?\n",
    "# print(dx.shape)\n",
    "# print(dx_num.shape)\n",
    "# print(db.shape)\n",
    "# print(db_num.shape)\n",
    "# The error should be around 1e-10\n",
    "print (\"dx Error: \", rel_error(dx_num, dx))\n",
    "print (\"dw Error: \", rel_error(dw_num, dw))\n",
    "print (\"db Error: \", rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU Forward\n",
    "In the class skeleton \"relu\", please complete the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -0.81818182 -0.63636364 -0.45454545]\n",
      " [-0.27272727 -0.09090909  0.09090909  0.27272727]\n",
      " [ 0.45454545  0.63636364  0.81818182  1.        ]]\n",
      "(3, 4)\n",
      "Difference:  5.00000005012e-09\n"
     ]
    }
   ],
   "source": [
    "# Test the relu forward function\n",
    "x = np.linspace(-1.0, 1.0, num=12).reshape(3, 4)\n",
    "relu_f = relu(name=\"relu_f\")\n",
    "print(x)\n",
    "print(x.shape)\n",
    "out = relu_f.forward(x)\n",
    "correct_out = np.array([[0.,          0.,        0.,         0.        ],\n",
    "                        [0.,          0.,        0.09090909, 0.27272727],\n",
    "                        [0.45454545, 0.63636364, 0.81818182, 1.        ]])\n",
    "\n",
    "# Compare your output with the above pre-computed ones. \n",
    "# The difference should not be larger than 1e-8\n",
    "print (\"Difference: \", rel_error(out, correct_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU Backward\n",
    "Please complete the backward pass of the class relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx Error:  3.27562692346e-12\n"
     ]
    }
   ],
   "source": [
    "# Test the relu backward function\n",
    "x = np.random.randn(10, 10)\n",
    "dout = np.random.randn(*x.shape)\n",
    "relu_b = relu(name=\"relu_b\")\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: relu_b.forward(x), x, dout)\n",
    "\n",
    "out = relu_b.forward(x)\n",
    "dx = relu_b.backward(dout)\n",
    "\n",
    "# The error should not be larger than 1e-10\n",
    "print (\"dx Error: \", rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Forward\n",
    "In the class \"dropout\", please complete the forward pass. Remember that the dropout is only applied during training phase, you should pay attention to this while implementing the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Dropout p =  0.25\n",
      "Mean of input:  5.00459031026\n",
      "Mean of output during training time:  3.71996795456\n",
      "Mean of output during testing time:  5.00459031026\n",
      "Fraction of output set to zero during training time:  0.2559\n",
      "Fraction of output set to zero during testing time:  0.0\n",
      "----------------------------------------------------------------\n",
      "Dropout p =  0.5\n",
      "Mean of input:  5.00459031026\n",
      "Mean of output during training time:  2.46732088623\n",
      "Mean of output during testing time:  5.00459031026\n",
      "Fraction of output set to zero during training time:  0.5059\n",
      "Fraction of output set to zero during testing time:  0.0\n",
      "----------------------------------------------------------------\n",
      "Dropout p =  0.75\n",
      "Mean of input:  5.00459031026\n",
      "Mean of output during training time:  1.23149146353\n",
      "Mean of output during testing time:  5.00459031026\n",
      "Fraction of output set to zero during training time:  0.753\n",
      "Fraction of output set to zero during testing time:  0.0\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(100, 100) + 5.0\n",
    "\n",
    "print (\"----------------------------------------------------------------\")\n",
    "for p in [0.25, 0.50, 0.75]:\n",
    "    dropout_f = dropout(p)\n",
    "    out = dropout_f.forward(x, True)\n",
    "    out_test = dropout_f.forward(x, False)\n",
    "\n",
    "    print (\"Dropout p = \", p)\n",
    "    print (\"Mean of input: \", x.mean())\n",
    "    print (\"Mean of output during training time: \", out.mean())\n",
    "    print (\"Mean of output during testing time: \", out_test.mean())\n",
    "    print (\"Fraction of output set to zero during training time: \", (out == 0).mean())\n",
    "    print (\"Fraction of output set to zero during testing time: \", (out_test == 0).mean())\n",
    "    print (\"----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Backward\n",
    "Please complete the backward pass. Again remember that the dropout is only applied during training phase, handle this in the backward pass as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx relative error:  1.89289788466e-11\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(5, 5) + 5\n",
    "dout = np.random.randn(*x.shape)\n",
    "\n",
    "p = 0.75\n",
    "dropout_b = dropout(p, seed=100)\n",
    "out = dropout_b.forward(x, True)\n",
    "dx = dropout_b.backward(dout)\n",
    "dx_num = eval_numerical_gradient_array(lambda xx: dropout_b.forward(xx, True), x, dout)\n",
    "\n",
    "# The error should not be larger than 1e-9\n",
    "print ('dx relative error: ', rel_error(dx, dx_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing cascaded layers: FC + ReLU\n",
    "Please find the TestFCReLU function in fully_conn.py under lib directory. <br />\n",
    "You only need to complete few lines of code in the TODO block. <br />\n",
    "Please design an FC --> ReLU two-layer-mini-network where the parameters of them match the given x, w, and b <br />\n",
    "Please insert the corresponding names you defined for each layer to param_name_w, and param_name_b respectively. <br />\n",
    "Here you only modify the param_name part, the _w, and _b are automatically assigned during network setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx error:  1.13598437673e-10\n",
      "dw error:  1.14872404377e-10\n",
      "db error:  3.27562531714e-12\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(2, 3, 4)  # the input features\n",
    "w = np.random.randn(12, 10)   # the weight of fc layer\n",
    "b = np.random.randn(10)       # the bias of fc layer\n",
    "dout = np.random.randn(2, 10) # the gradients to the output, notice the shape\n",
    "\n",
    "tiny_net = TestFCReLU()\n",
    "\n",
    "# tiny_net.net.assign(\"param_name_w\", w)\n",
    "# tiny_net.net.assign(\"param_name_b\", b)\n",
    "tiny_net.net.assign(\"fc_w\", w)\n",
    "tiny_net.net.assign(\"fc_b\", b)\n",
    "\n",
    "out = tiny_net.forward(x)\n",
    "dx = tiny_net.backward(dout)\n",
    "\n",
    "dw = tiny_net.net.get_grads(\"fc_w\")\n",
    "db = tiny_net.net.get_grads(\"fc_b\")\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: tiny_net.forward(x), x, dout)\n",
    "dw_num = eval_numerical_gradient_array(lambda w: tiny_net.forward(x), w, dout)\n",
    "db_num = eval_numerical_gradient_array(lambda b: tiny_net.forward(x), b, dout)\n",
    "\n",
    "# The errors should not be larger than 1e-7\n",
    "print (\"dx error: \", rel_error(dx_num, dx))\n",
    "print (\"dw error: \", rel_error(dw_num, dw))\n",
    "print (\"db error: \", rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SoftMax Function and Loss Layer\n",
    "In the layer_utils.py, please first complete the function softmax, which will be use in the function cross_entropy. Please refer to the lecture slides of the mathematical expressions of the cross entropy loss function, and complete its forward pass and backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss:  1.60945846468\n",
      "dx error:  3.28599046685e-09\n"
     ]
    }
   ],
   "source": [
    "num_classes, num_inputs = 5, 50\n",
    "x = 0.001 * np.random.randn(num_inputs, num_classes)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "# print(y)\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "# print(y.size)\n",
    "test_loss = cross_entropy()\n",
    "loss = test_loss.forward(x, y)\n",
    "# print(\"loss\")\n",
    "# print(\"loss\")\n",
    "dx_num = eval_numerical_gradient(lambda x: test_loss.forward(x, y), x, verbose=False)\n",
    "\n",
    "loss = test_loss.forward(x, y)\n",
    "dx = test_loss.backward()\n",
    "\n",
    "# Test softmax_loss function. Loss should be around 1.609\n",
    "# and dx error should be at the scale of 1e-8 (or smaller)\n",
    "print (\"Cross Entropy Loss: \", loss)\n",
    "print (\"dx error: \", rel_error(dx_num, dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a Small Fully Connected Network\n",
    "Please find the SmallFullyConnectedNetwork function in fully_conn.py under lib directory. <br />\n",
    "Again you only need to complete few lines of code in the TODO block. <br />\n",
    "Please design an FC --> ReLU --> FC --> ReLU network where the shapes of parameters match the given shapes <br />\n",
    "Please insert the corresponding names you defined for each layer to param_name_w, and param_name_b respectively. <br />\n",
    "Here you only modify the param_name part, the _w, and _b are automatically assigned during network setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ... \n",
      "Passed!\n",
      "Testing test-time forward pass ... \n",
      "Passed!\n",
      "Testing the loss ...\n",
      "Passed!\n",
      "Testing the gradients (error should be no larger than 1e-7) ...\n",
      "fc1_b relative error: 2.85e-09\n",
      "fc1_w relative error: 8.75e-09\n",
      "fc2_b relative error: 6.71e-08\n",
      "fc2_w relative error: 2.59e-09\n"
     ]
    }
   ],
   "source": [
    "model = SmallFullyConnectedNetwork()\n",
    "loss_func = cross_entropy()\n",
    "\n",
    "N, D, = 4, 4  # N: batch size, D: input dimension\n",
    "H, C  = 30, 7 # H: hidden dimension, C: output dimension\n",
    "std = 0.02\n",
    "x = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=N)\n",
    "\n",
    "print (\"Testing initialization ... \")\n",
    "w1_std = abs(model.net.get_params(\"fc1_w\").std() - std)\n",
    "b1 = model.net.get_params(\"fc1_b\").std()\n",
    "w2_std = abs(model.net.get_params(\"fc2_w\").std() - std)\n",
    "b2 = model.net.get_params(\"fc2_b\").std()\n",
    "\n",
    "assert w1_std < std / 10, \"First layer weights do not seem right\"\n",
    "assert np.all(b1 == 0), \"First layer biases do not seem right\"\n",
    "assert w2_std < std / 10, \"Second layer weights do not seem right\"\n",
    "assert np.all(b2 == 0), \"Second layer biases do not seem right\"\n",
    "print (\"Passed!\")\n",
    "\n",
    "print (\"Testing test-time forward pass ... \")\n",
    "w1 = np.linspace(-0.7, 0.3, num=D*H).reshape(D, H)\n",
    "w2 = np.linspace(-0.3, 0.4, num=H*C).reshape(H, C)\n",
    "b1 = np.linspace(-0.1, 0.9, num=H)\n",
    "b2 = np.linspace(-0.9, 0.1, num=C)\n",
    "\n",
    "model.net.assign(\"fc1_w\", w1)\n",
    "model.net.assign(\"fc1_b\", b1)\n",
    "model.net.assign(\"fc2_w\", w2)\n",
    "model.net.assign(\"fc2_b\", b2)\n",
    "\n",
    "feats = np.linspace(-5.5, 4.5, num=N*D).reshape(D, N).T\n",
    "scores = model.forward(feats)\n",
    "correct_scores = np.asarray([[4.20670862, 4.87188359, 5.53705856, 6.20223352, 6.86740849, 7.53258346, 8.19775843],\n",
    "                             [4.74826036, 5.35984681, 5.97143326, 6.58301972, 7.19460617, 7.80619262, 8.41777907],\n",
    "                             [5.2898121,  5.84781003, 6.40580797, 6.96380591, 7.52180384, 8.07980178, 8.63779971],\n",
    "                             [5.83136384, 6.33577326, 6.84018268, 7.3445921,  7.84900151, 8.35341093, 8.85782035]])\n",
    "scores_diff = np.sum(np.abs(scores - correct_scores))\n",
    "assert scores_diff < 1e-6, \"Your implementation might went wrong!\"\n",
    "print (\"Passed!\")\n",
    "\n",
    "print (\"Testing the loss ...\",)\n",
    "y = np.asarray([0, 5, 1, 4])\n",
    "loss = loss_func.forward(scores, y)\n",
    "dLoss = loss_func.backward()\n",
    "correct_loss = 2.90181552716\n",
    "assert abs(loss - correct_loss) < 1e-10, \"Your implementation might went wrong!\"\n",
    "print (\"Passed!\")\n",
    "\n",
    "print (\"Testing the gradients (error should be no larger than 1e-7) ...\")\n",
    "din = model.backward(dLoss)\n",
    "for layer in model.net.layers:\n",
    "    if not layer.params:\n",
    "        continue\n",
    "    for name in sorted(layer.grads):\n",
    "        f = lambda _: loss_func.forward(model.forward(feats), y)\n",
    "        grad_num = eval_numerical_gradient(f, layer.params[name], verbose=False)\n",
    "        print ('%s relative error: %.2e' % (name, rel_error(grad_num, layer.grads[name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test a Fully Connected Network regularized with Dropout\n",
    "Please find the DropoutNet function in fully_conn.py under lib directory. <br />\n",
    "For this part you don't need to design a new network, just simply run the following test code <br />\n",
    "If something goes wrong, you might want to double check your dropout implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout p = 0.0\n",
      "Loss (should be ~2.30) :  2.30285163514\n",
      "Error of gradients should be no larger than 1e-5\n",
      "fc1_b relative error: 3.86706745047462e-08\n",
      "fc1_w relative error: 1.6842808381819982e-06\n",
      "fc2_b relative error: 3.812098660929502e-09\n",
      "fc2_w relative error: 2.2678596223853193e-06\n",
      "fc3_b relative error: 1.524817329248913e-10\n",
      "fc3_w relative error: 1.169622219539072e-07\n",
      "Dropout p = 0.25\n",
      "Loss (should be ~2.30) :  2.30217644162\n",
      "Error of gradients should be no larger than 1e-5\n",
      "fc1_b relative error: 6.475101867894039e-08\n",
      "fc1_w relative error: 6.062712717230874e-06\n",
      "fc2_b relative error: 1.508710003974928e-08\n",
      "fc2_w relative error: 3.811195240195112e-05\n",
      "fc3_b relative error: 4.200665244051176e-10\n",
      "fc3_w relative error: 5.871051889990535e-07\n",
      "Dropout p = 0.5\n",
      "Loss (should be ~2.30) :  2.30350883178\n",
      "Error of gradients should be no larger than 1e-5\n",
      "fc1_b relative error: 1.3676466073508024e-07\n",
      "fc1_w relative error: 2.8970630397677172e-06\n",
      "fc2_b relative error: 5.655416664888587e-07\n",
      "fc2_w relative error: 5.0713922376764954e-05\n",
      "fc3_b relative error: 2.606178473769169e-10\n",
      "fc3_w relative error: 3.237269669833194e-07\n"
     ]
    }
   ],
   "source": [
    "N, D, C = 3, 15, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "seed = 123\n",
    "\n",
    "for dropout_p in [0., 0.25, 0.5]:\n",
    "    print (\"Dropout p =\", dropout_p)\n",
    "    model = DropoutNet(dropout_p=dropout_p, seed=seed)\n",
    "    loss_func = cross_entropy()\n",
    "    output = model.forward(X, True)\n",
    "    loss = loss_func.forward(output, y)\n",
    "    dLoss = loss_func.backward()\n",
    "    dX = model.backward(dLoss)\n",
    "    grads = model.net.grads\n",
    "    print (\"Loss (should be ~2.30) : \", loss)\n",
    "\n",
    "    print (\"Error of gradients should be no larger than 1e-5\")\n",
    "    for name in sorted(model.net.params):\n",
    "        f = lambda _: loss_func.forward(model.forward(X, True), y)\n",
    "        grad_num = eval_numerical_gradient(f, model.net.params[name], verbose=False, h=1e-5)\n",
    "        print (\"{} relative error: {}\".format(name, rel_error(grad_num, grads[name])))\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Network\n",
    "In this section, we defined a TinyNet class for you to fill in the TODO block in fully_conn.py.\n",
    "* Here please design a two layer fully connected network for this part.\n",
    "* Please read the train.py under lib directory carefully and complete the TODO blocks in the train_net function first.\n",
    "* In addition, read how the SGD function is implemented in optim.py, you will be asked to complete three other optimization methods in the later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Arrange the data\n",
    "data_dict = {\n",
    "    \"data_train\": (data[\"data_train\"], data[\"labels_train\"]),\n",
    "    \"data_val\": (data[\"data_val\"], data[\"labels_val\"]),\n",
    "    \"data_test\": (data[\"data_test\"], data[\"labels_test\"])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 3, 32, 32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['data_train'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3, 32, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['data_val'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['data_test'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyNet()\n",
    "loss_f = cross_entropy()\n",
    "optimizer = SGD(model.net, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now train the network to achieve at least 50% validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = None\n",
    "#############################################################################\n",
    "# TODO: Use the train_net function you completed to train a network         #\n",
    "#############################################################################\n",
    "results = train_net(data_dict, model, loss_f, optimizer, batch_size=128, max_epochs=10)\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "opt_params, loss_hist, train_acc_hist, val_acc_hist = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fc1_w', 'fc1_b', 'fc2_w', 'fc2_b'])\n"
     ]
    }
   ],
   "source": [
    "# Take a look at what names of params were stored\n",
    "print (opt_params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Params: fc1_w Shape: (3072, 500)\n",
      "Loading Params: fc1_b Shape: (500,)\n",
      "Loading Params: fc2_w Shape: (500, 10)\n",
      "Loading Params: fc2_b Shape: (10,)\n",
      "Validation Accuracy: 32.2%\n",
      "Testing Accuracy: 32.4%\n"
     ]
    }
   ],
   "source": [
    "# Demo: How to load the parameters to a newly defined network\n",
    "model = TinyNet()\n",
    "model.net.load(opt_params)\n",
    "val_acc = compute_acc(model, data[\"data_val\"], data[\"labels_val\"])\n",
    "print (\"Validation Accuracy: {}%\".format(val_acc*100))\n",
    "test_acc = compute_acc(model, data[\"data_test\"], data[\"labels_test\"])\n",
    "print (\"Testing Accuracy: {}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAALJCAYAAADielEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1188597b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning curves\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "loss_hist_ = loss_hist[1::100] # sparse the curve a bit\n",
    "plt.plot(loss_hist_, '-o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(train_acc_hist, '-o', label='Training')\n",
    "plt.plot(val_acc_hist, '-o', label='Validation')\n",
    "plt.plot([0.5] * len(val_acc_hist), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Optimizers\n",
    "There are several more advanced optimizers than vanilla SGD, you will implement three more sophisticated and widely-used methods in this section. Please complete the TODOs in the optim.py under lib directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD + Momentum\n",
    "The update rule of SGD plus momentum is as shown below: <br\\ >\n",
    "\\begin{equation}\n",
    "v_t: velocity \\\\\n",
    "\\gamma: momentum \\\\\n",
    "\\eta: learning\\ rate \\\\\n",
    "v_t = \\gamma v_{t-1} + \\eta \\nabla_{\\theta}J(\\theta) \\\\\n",
    "\\theta = \\theta - v_t\n",
    "\\end{equation}\n",
    "Complete the SGDM() function in optim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SGD with momentum\n",
    "model = TinyNet()\n",
    "loss_f = cross_entropy()\n",
    "optimizer = SGD(model.net, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the implementation of SGD with Momentum\n",
    "N, D = 4, 5\n",
    "test_sgd = sequential(fc(N, D, name=\"sgd_fc\"))\n",
    "\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "test_sgd.layers[0].params = {\"sgd_fc_w\": w}\n",
    "test_sgd.layers[0].grads = {\"sgd_fc_w\": dw}\n",
    "\n",
    "test_sgd_momentum = SGDM(test_sgd, 1e-3, 0.9)\n",
    "test_sgd_momentum.velocity = {\"sgd_fc_w\": v}\n",
    "test_sgd_momentum.step()\n",
    "\n",
    "updated_w = test_sgd.layers[0].params[\"sgd_fc_w\"]\n",
    "velocity = test_sgd_momentum.velocity[\"sgd_fc_w\"]\n",
    "\n",
    "expected_updated_w = np.asarray([\n",
    "  [ 0.1406,      0.20738947,  0.27417895,  0.34096842,  0.40775789],\n",
    "  [ 0.47454737,  0.54133684,  0.60812632,  0.67491579,  0.74170526],\n",
    "  [ 0.80849474,  0.87528421,  0.94207368,  1.00886316,  1.07565263],\n",
    "  [ 1.14244211,  1.20923158,  1.27602105,  1.34281053,  1.4096    ]])\n",
    "expected_velocity = np.asarray([\n",
    "  [ 0.5406,      0.55475789,  0.56891579, 0.58307368,  0.59723158],\n",
    "  [ 0.61138947,  0.62554737,  0.63970526,  0.65386316,  0.66802105],\n",
    "  [ 0.68217895,  0.69633684,  0.71049474,  0.72465263,  0.73881053],\n",
    "  [ 0.75296842,  0.76712632,  0.78128421,  0.79544211,  0.8096    ]])\n",
    "\n",
    "print ('updated_w error: ', rel_error(updated_w, expected_updated_w))\n",
    "print ('velocity error: ', rel_error(expected_velocity, velocity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code block to train a multi-layer fully connected network with both SGD and SGD plus Momentum. The network trained with SGDM optimizer should converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Arrange a small data\n",
    "num_train = 4000\n",
    "small_data_dict = {\n",
    "    \"data_train\": (data[\"data_train\"][:num_train], data[\"labels_train\"][:num_train]),\n",
    "    \"data_val\": (data[\"data_val\"], data[\"labels_val\"]),\n",
    "    \"data_test\": (data[\"data_test\"], data[\"labels_test\"])\n",
    "}\n",
    "\n",
    "model_sgd      = FullyConnectedNetwork()\n",
    "model_sgdm     = FullyConnectedNetwork()\n",
    "loss_f_sgd     = cross_entropy()\n",
    "loss_f_sgdm    = cross_entropy()\n",
    "optimizer_sgd  = SGD(model_sgd.net, 1e-2)\n",
    "optimizer_sgdm = SGDM(model_sgdm.net, 1e-2, 0.9)\n",
    "\n",
    "print (\"Training with Vanilla SGD...\")\n",
    "results_sgd = train_net(small_data_dict, model_sgd, loss_f_sgd, optimizer_sgd, batch_size=100, \n",
    "                        max_epochs=5, show_every=100, verbose=True)\n",
    "\n",
    "print (\"\\nTraining with SGD plus Momentum...\")\n",
    "results_sgdm = train_net(small_data_dict, model_sgdm, loss_f_sgdm, optimizer_sgdm, batch_size=100, \n",
    "                         max_epochs=5, show_every=100, verbose=True)\n",
    "\n",
    "opt_params_sgd,  loss_hist_sgd,  train_acc_hist_sgd,  val_acc_hist_sgd  = results_sgd\n",
    "opt_params_sgdm, loss_hist_sgdm, train_acc_hist_sgdm, val_acc_hist_sgdm = results_sgdm\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(loss_hist_sgd, 'o', label=\"Vanilla SGD\")\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(train_acc_hist_sgd, '-o', label=\"Vanilla SGD\")\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(val_acc_hist_sgd, '-o', label=\"Vanilla SGD\")\n",
    "         \n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(loss_hist_sgdm, 'o', label=\"SGD with Momentum\")\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(train_acc_hist_sgdm, '-o', label=\"SGD with Momentum\")\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(val_acc_hist_sgdm, '-o', label=\"SGD with Momentum\")\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp\n",
    "The update rule of RMSProp is as shown below: <br\\ >\n",
    "\\begin{equation}\n",
    "\\gamma: decay\\ rate \\\\\n",
    "\\epsilon: small\\ number \\\\\n",
    "g_t^2: squared\\ gradients \\\\\n",
    "\\eta: learning\\ rate \\\\\n",
    "E[g^2]_t: decaying\\ average\\ of\\ past\\ squared\\ gradients\\ at\\ update\\ step\\ t \\\\\n",
    "E[g^2]_t = \\gamma E[g^2]_{t-1} + (1-\\gamma)g_t^2 \\\\\n",
    "\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{E[g^2]_t+\\epsilon}}\n",
    "\\end{equation}\n",
    "Complete the RMSProp() function in optim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test RMSProp implementation; you should see errors less than 1e-7\n",
    "N, D = 4, 5\n",
    "test_rms = sequential(fc(N, D, name=\"rms_fc\"))\n",
    "\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "cache = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "\n",
    "test_rms.layers[0].params = {\"rms_fc_w\": w}\n",
    "test_rms.layers[0].grads = {\"rms_fc_w\": dw}\n",
    "\n",
    "opt_rms = RMSProp(test_rms, 1e-2, 0.99)\n",
    "opt_rms.cache = {\"rms_fc_w\": cache}\n",
    "opt_rms.step()\n",
    "\n",
    "updated_w = test_rms.layers[0].params[\"rms_fc_w\"]\n",
    "cache = opt_rms.cache[\"rms_fc_w\"]\n",
    "\n",
    "expected_updated_w = np.asarray([\n",
    "  [-0.39223849, -0.34037513, -0.28849239, -0.23659121, -0.18467247],\n",
    "  [-0.132737,   -0.08078555, -0.02881884,  0.02316247,  0.07515774],\n",
    "  [ 0.12716641,  0.17918792,  0.23122175,  0.28326742,  0.33532447],\n",
    "  [ 0.38739248,  0.43947102,  0.49155973,  0.54365823,  0.59576619]])\n",
    "expected_cache = np.asarray([\n",
    "  [ 0.5976,      0.6126277,   0.6277108,   0.64284931,  0.65804321],\n",
    "  [ 0.67329252,  0.68859723,  0.70395734,  0.71937285,  0.73484377],\n",
    "  [ 0.75037008,  0.7659518,   0.78158892,  0.79728144,  0.81302936],\n",
    "  [ 0.82883269,  0.84469141,  0.86060554,  0.87657507,  0.8926    ]])\n",
    "\n",
    "print ('updated_w error: ', rel_error(expected_updated_w, updated_w))\n",
    "print ('cache error: ', rel_error(expected_cache, opt_rms.cache[\"rms_fc_w\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam\n",
    "The update rule of Adam is as shown below: <br\\ >\n",
    "\\begin{equation}\n",
    "g_t: gradients\\ at\\ update\\ step\\ t \\\\\n",
    "m_t = \\beta_1m_{t-1} + (1-\\beta_1)g_t \\\\\n",
    "v_t = \\beta_2v_{t-1} + (1-\\beta_1)g_t^2 \\\\\n",
    "\\hat{m_t}: bias\\ corrected\\ m_t \\\\\n",
    "\\hat{v_t}: bias\\ corrected\\ v_t \\\\\n",
    "\\theta_{t+1} = \\theta_t - \\frac{\\eta}{\\sqrt{\\hat{v_t}}+\\epsilon}\n",
    "\\end{equation}\n",
    "Complete the Adam() function in optim.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test Adam implementation; you should see errors around 1e-7 or less\n",
    "N, D = 4, 5\n",
    "test_adam = sequential(fc(N, D, name=\"adam_fc\"))\n",
    "\n",
    "w = np.linspace(-0.4, 0.6, num=N*D).reshape(N, D)\n",
    "dw = np.linspace(-0.6, 0.4, num=N*D).reshape(N, D)\n",
    "m = np.linspace(0.6, 0.9, num=N*D).reshape(N, D)\n",
    "v = np.linspace(0.7, 0.5, num=N*D).reshape(N, D)\n",
    "\n",
    "test_adam.layers[0].params = {\"adam_fc_w\": w}\n",
    "test_adam.layers[0].grads = {\"adam_fc_w\": dw}\n",
    "\n",
    "opt_adam = Adam(test_adam, 1e-2, 0.9, 0.999, t=5)\n",
    "opt_adam.mt = {\"adam_fc_w\": m}\n",
    "opt_adam.vt = {\"adam_fc_w\": v}\n",
    "opt_adam.step()\n",
    "\n",
    "updated_w = test_adam.layers[0].params[\"adam_fc_w\"]\n",
    "mt = opt_adam.mt[\"adam_fc_w\"]\n",
    "vt = opt_adam.vt[\"adam_fc_w\"]\n",
    "\n",
    "expected_updated_w = np.asarray([\n",
    "  [-0.40094747, -0.34836187, -0.29577703, -0.24319299, -0.19060977],\n",
    "  [-0.1380274,  -0.08544591, -0.03286534,  0.01971428,  0.0722929],\n",
    "  [ 0.1248705,   0.17744702,  0.23002243,  0.28259667,  0.33516969],\n",
    "  [ 0.38774145,  0.44031188,  0.49288093,  0.54544852,  0.59801459]])\n",
    "expected_v = np.asarray([\n",
    "  [ 0.69966,     0.68908382,  0.67851319,  0.66794809,  0.65738853,],\n",
    "  [ 0.64683452,  0.63628604,  0.6257431,   0.61520571,  0.60467385,],\n",
    "  [ 0.59414753,  0.58362676,  0.57311152,  0.56260183,  0.55209767,],\n",
    "  [ 0.54159906,  0.53110598,  0.52061845,  0.51013645,  0.49966,   ]])\n",
    "expected_m = np.asarray([\n",
    "  [ 0.48,        0.49947368,  0.51894737,  0.53842105,  0.55789474],\n",
    "  [ 0.57736842,  0.59684211,  0.61631579,  0.63578947,  0.65526316],\n",
    "  [ 0.67473684,  0.69421053,  0.71368421,  0.73315789,  0.75263158],\n",
    "  [ 0.77210526,  0.79157895,  0.81105263,  0.83052632,  0.85      ]])\n",
    "\n",
    "print ('updated_w error: ', rel_error(expected_updated_w, updated_w))\n",
    "print ('mt error: ', rel_error(expected_m, mt))\n",
    "print ('vt error: ', rel_error(expected_v, vt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the optimizers\n",
    "Run the following code block to compare the plotted results among all the above optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_rms      = FullyConnectedNetwork()\n",
    "model_adam     = FullyConnectedNetwork()\n",
    "loss_f_rms     = cross_entropy()\n",
    "loss_f_adam    = cross_entropy()\n",
    "optimizer_rms  = RMSProp(model_rms.net, 5e-4)\n",
    "optimizer_adam = Adam(model_adam.net, 5e-4)\n",
    "\n",
    "print (\"Training with RMSProp...\")\n",
    "results_rms = train_net(small_data_dict, model_rms, loss_f_rms, optimizer_rms, batch_size=100, \n",
    "                        max_epochs=5, show_every=100, verbose=True)\n",
    "\n",
    "print (\"\\nTraining with Adam...\")\n",
    "results_adam = train_net(small_data_dict, model_adam, loss_f_adam, optimizer_adam, batch_size=100, \n",
    "                         max_epochs=5, show_every=100, verbose=True)\n",
    "\n",
    "opt_params_rms,  loss_hist_rms,  train_acc_hist_rms,  val_acc_hist_rms  = results_rms\n",
    "opt_params_adam, loss_hist_adam, train_acc_hist_adam, val_acc_hist_adam = results_adam\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.title('Training accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.title('Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(loss_hist_sgd, 'o', label=\"Vanilla SGD\")\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(train_acc_hist_sgd, '-o', label=\"Vanilla SGD\")\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(val_acc_hist_sgd, '-o', label=\"Vanilla SGD\")\n",
    "         \n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(loss_hist_sgdm, 'o', label=\"SGD with Momentum\")\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(train_acc_hist_sgdm, '-o', label=\"SGD with Momentum\")\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(val_acc_hist_sgdm, '-o', label=\"SGD with Momentum\")\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(loss_hist_rms, 'o', label=\"RMSProp\")\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(train_acc_hist_rms, '-o', label=\"RMSProp\")\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(val_acc_hist_rms, '-o', label=\"RMSProp\")\n",
    "         \n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(loss_hist_adam, 'o', label=\"Adam\")\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(train_acc_hist_adam, '-o', label=\"Adam\")\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(val_acc_hist_adam, '-o', label=\"Adam\")\n",
    "  \n",
    "for i in [1, 2, 3]:\n",
    "  plt.subplot(3, 1, i)\n",
    "  plt.legend(loc='upper center', ncol=4)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Network with Dropout\n",
    "Run the following code blocks to compare the results with and without dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train two identical nets, one with dropout and one without\n",
    "num_train = 500\n",
    "data_dict_500 = {\n",
    "    \"data_train\": (data[\"data_train\"][:num_train], data[\"labels_train\"][:num_train]),\n",
    "    \"data_val\": (data[\"data_val\"], data[\"labels_val\"]),\n",
    "    \"data_test\": (data[\"data_test\"], data[\"labels_test\"])\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "dropout_ps = [0, 0.25]  # you can try some dropout prob yourself\n",
    "\n",
    "results_dict = {}\n",
    "for dropout_p in dropout_ps:\n",
    "    results_dict[dropout_p] = {}\n",
    "\n",
    "for dropout_p in dropout_ps:\n",
    "    print (\"Dropout =\", dropout_p)\n",
    "    model = DropoutNetTest(dropout_p=dropout_p)\n",
    "    loss_f = cross_entropy()\n",
    "    optimizer = SGDM(model.net, 1e-4)\n",
    "    results = train_net(data_dict_500, model, loss_f, optimizer, batch_size=100, \n",
    "                        max_epochs=20, show_every=100, verbose=True)\n",
    "    opt_params, loss_hist, train_acc_hist, val_acc_hist = results\n",
    "    results_dict[dropout_p] = {\n",
    "        \"opt_params\": opt_params, \n",
    "        \"loss_hist\": loss_hist, \n",
    "        \"train_acc_hist\": train_acc_hist, \n",
    "        \"val_acc_hist\": val_acc_hist\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot train and validation accuracies of the two models\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "for dropout_p in dropout_ps:\n",
    "    curr_dict = results_dict[dropout_p]\n",
    "    train_accs.append(curr_dict[\"train_acc_hist\"][-1])\n",
    "    val_accs.append(curr_dict[\"val_acc_hist\"][-1])\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "for dropout_p in dropout_ps:\n",
    "    curr_dict = results_dict[dropout_p]\n",
    "    plt.plot(curr_dict[\"train_acc_hist\"], 'o', label='%.2f dropout' % dropout_p)\n",
    "plt.title('Train accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "  \n",
    "plt.subplot(3, 1, 2)\n",
    "for dropout_p in dropout_ps:\n",
    "    curr_dict = results_dict[dropout_p]\n",
    "    plt.plot(curr_dict[\"val_acc_hist\"], 'o', label='%.2f dropout' % dropout_p)\n",
    "plt.title('Val accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inline Question: Describe what you observe from the above results and graphs\n",
    "#### Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Activation Functions\n",
    "In each of the activation function, use the given lambda function template to plot their corresponding curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "left, right = -10, 10\n",
    "X  = np.linspace(left, right, 100)\n",
    "XS = np.linspace(-5, 5, 10)\n",
    "lw = 4\n",
    "alpha = 0.1\n",
    "elu_alpha = 0.5\n",
    "selu_alpha = 1.6732\n",
    "selu_scale = 1.0507\n",
    "\n",
    "#########################\n",
    "####### YOUR CODE #######\n",
    "#########################\n",
    "sigmoid = lambda x: x\n",
    "leaky_relu = lambda x: x\n",
    "relu = lambda x: x\n",
    "elu = lambda x: x\n",
    "selu = lambda x: x\n",
    "tanh = lambda x: x\n",
    "#########################\n",
    "### END OF YOUR CODE ####\n",
    "#########################\n",
    "\n",
    "activations = {\n",
    "    \"Sigmoid\": sigmoid,\n",
    "    \"LeakyReLU\": leaky_relu,\n",
    "    \"ReLU\": relu,\n",
    "    \"ELU\": elu,\n",
    "    \"SeLU\": selu,\n",
    "    \"Tanh\": tanh\n",
    "}\n",
    "\n",
    "# Ground Truth activations\n",
    "GT_Act = {\n",
    "    \"Sigmoid\": [0.00669285092428, 0.0200575365379, 0.0585369028744, 0.158869104881, 0.364576440742, \n",
    "                0.635423559258, 0.841130895119, 0.941463097126, 0.979942463462, 0.993307149076],\n",
    "    \"LeakyReLU\": [-0.5, -0.388888888889, -0.277777777778, -0.166666666667, -0.0555555555556, \n",
    "                  0.555555555556, 1.66666666667, 2.77777777778, 3.88888888889, 5.0],\n",
    "    \"ReLU\": [-0.0, -0.0, -0.0, -0.0, -0.0, 0.555555555556, 1.66666666667, 2.77777777778, 3.88888888889, 5.0],\n",
    "    \"ELU\": [-0.4966310265, -0.489765962143, -0.468911737989, -0.405562198581, -0.213123289631, \n",
    "            0.555555555556, 1.66666666667, 2.77777777778, 3.88888888889, 5.0],\n",
    "    \"SeLU\": [-1.74618571868, -1.72204772347, -1.64872296837, -1.42598202974, -0.749354802287, \n",
    "             0.583722222222, 1.75116666667, 2.91861111111, 4.08605555556, 5.2535],\n",
    "    \"Tanh\": [-0.999909204263, -0.999162466631, -0.992297935288, -0.931109608668, -0.504672397722, \n",
    "             0.504672397722, 0.931109608668, 0.992297935288, 0.999162466631, 0.999909204263]\n",
    "} \n",
    "\n",
    "for label in activations:\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(X, activations[label](X), color='darkorchid', lw=lw, label=label)\n",
    "    assert rel_error(activations[label](XS), GT_Act[label]) < 1e-9, \\\n",
    "           \"Your implementation of {} might be wrong\".format(label)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.axhline(0, color='black')\n",
    "    ax.axvline(0, color='black')\n",
    "    ax.set_title('{}'.format(label), fontsize=14)\n",
    "    plt.xlabel(r\"X\")\n",
    "    plt.ylabel(r\"Y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Phew! You're done for problem 1 now, but 3 more to go... LOL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
